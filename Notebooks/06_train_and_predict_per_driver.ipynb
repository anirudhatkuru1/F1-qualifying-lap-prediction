{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc62c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched file not found. Loading processed file: ..\\data\\processed_quali_2024.csv\n",
      "Rows: 917\n",
      "Columns: ['meeting_key', 'session_key', 'driver_number', 'lap_number', 'date_start', 'duration_sector_1', 'duration_sector_2', 'duration_sector_3', 'i1_speed', 'i2_speed', 'is_pit_out_lap', 'lap_duration', 'segments_sector_1', 'segments_sector_2', 'segments_sector_3', 'st_speed', 'sector_sum', 'avg_speed_est']\n",
      "Found 5 meetings (ordered). Example keys: [np.int64(1254), np.int64(1255), np.int64(1256), np.int64(1257), np.int64(1258)]\n",
      "Enter the race number you want to predict (1-based index). E.g., 5 to predict 5th race using 1-4 for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "race_to_predict must be between 1 and 5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUsing default race_to_predict =\u001b[39m\u001b[33m\"\u001b[39m, race_to_predict)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m1\u001b[39m <= race_to_predict <= \u001b[38;5;28mlen\u001b[39m(meetings)):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrace_to_predict must be between 1 and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(meetings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m train_meetings = meetings[:race_to_predict - \u001b[32m1\u001b[39m]\n\u001b[32m     70\u001b[39m test_meeting = meetings[race_to_predict - \u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: race_to_predict must be between 1 and 5"
     ]
    }
   ],
   "source": [
    "# notebooks/06_train_and_predict_per_driver.ipynb\n",
    "# Title: Train & Predict Per-Driver Quali Lap (dynamic race number)\n",
    "# Run this in the project venv kernel.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Helper: load best available data ----------\n",
    "def load_best_data():\n",
    "    # Prefer enriched file if exists, else processed, else all_quali\n",
    "    enriched = DATA_DIR / \"enriched_quali_2024.csv\"\n",
    "    processed = DATA_DIR / \"processed_quali_2024.csv\"\n",
    "    all_quali = DATA_DIR / \"all_quali_2024.csv\"\n",
    "    \n",
    "    if enriched.exists():\n",
    "        print(\"Loading enriched data:\", enriched)\n",
    "        df = pd.read_csv(enriched, parse_dates=[\"date_start\"])\n",
    "    elif processed.exists():\n",
    "        print(\"Enriched file not found. Loading processed file:\", processed)\n",
    "        df = pd.read_csv(processed, parse_dates=[\"date_start\"])\n",
    "        # best-effort: try to enrich with drivers/teams/tyres if endpoints are available\n",
    "        # but we do not attempt heavy enrichment here; assume earlier step created mapping\n",
    "    elif all_quali.exists():\n",
    "        print(\"Only raw all_quali_2024.csv found. Loading it:\", all_quali)\n",
    "        df = pd.read_csv(all_quali, parse_dates=[\"date_start\"])\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No data files found in ../data. Please run earlier notebooks (fetch & process).\")\n",
    "    return df\n",
    "\n",
    "df = load_best_data()\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n",
    "\n",
    "# ---------- Ask user which race number to predict ----------\n",
    "# We use meeting_key ordering to define race number ordering\n",
    "meetings = sorted(df[\"meeting_key\"].unique())\n",
    "print(f\"Found {len(meetings)} meetings (ordered). Example keys: {meetings[:8]}\")\n",
    "print(\"Enter the race number you want to predict (1-based index). E.g., 5 to predict 5th race using 1-4 for training.\")\n",
    "\n",
    "# For notebook convenience use input(); in VS Code Jupyter you can set race_number variable manually\n",
    "try:\n",
    "    race_to_predict = int(input(\"Race number to predict (1-based): \").strip())\n",
    "except:\n",
    "    # fallback: default to 5 if running non-interactively\n",
    "    race_to_predict = 5\n",
    "    print(\"Using default race_to_predict =\", race_to_predict)\n",
    "\n",
    "if not (1 <= race_to_predict <= len(meetings)):\n",
    "    raise ValueError(f\"race_to_predict must be between 1 and {len(meetings)}\")\n",
    "\n",
    "train_meetings = meetings[:race_to_predict - 1]\n",
    "test_meeting = meetings[race_to_predict - 1]\n",
    "print(\"Training meetings (keys):\", train_meetings)\n",
    "print(\"Testing meeting (key):\", test_meeting)\n",
    "\n",
    "# ---------- Filter train/test ----------\n",
    "train_df = df[df[\"meeting_key\"].isin(train_meetings)].copy()\n",
    "test_df = df[df[\"meeting_key\"] == test_meeting].copy()\n",
    "\n",
    "print(\"Train rows:\", train_df.shape)\n",
    "print(\"Test rows :\", test_df.shape)\n",
    "\n",
    "# ---------- Minimal cleaning & ensure required columns exist ----------\n",
    "required_cols = [\"meeting_key\",\"session_key\",\"driver_number\",\"lap_number\",\"lap_duration\",\n",
    "                 \"duration_sector_1\",\"duration_sector_2\",\"duration_sector_3\",\n",
    "                 \"i1_speed\",\"i2_speed\",\"st_speed\",\"date_start\"]\n",
    "for c in required_cols:\n",
    "    if c not in df.columns:\n",
    "        raise KeyError(f\"Required column missing: {c}. Please check processed/enriched dataset.\")\n",
    "\n",
    "# Convert numeric columns\n",
    "num_cols = [\"lap_number\",\"lap_duration\",\"duration_sector_1\",\"duration_sector_2\",\"duration_sector_3\",\n",
    "            \"i1_speed\",\"i2_speed\",\"st_speed\"]\n",
    "for c in num_cols:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\")\n",
    "    test_df[c] = pd.to_numeric(test_df[c], errors=\"coerce\")\n",
    "\n",
    "# If driver_name/team_name exist, good â€” else we'll aggregate by driver_number/team mapping must exist\n",
    "has_driver_name = \"driver_name\" in df.columns\n",
    "has_team_name = \"team_name\" in df.columns\n",
    "\n",
    "if not has_driver_name:\n",
    "    print(\"WARNING: driver_name not present. Predictions will use driver_number as identifier.\")\n",
    "else:\n",
    "    print(\"driver_name column available.\")\n",
    "\n",
    "if not has_team_name:\n",
    "    print(\"WARNING: team_name not present. Consider creating driver-team mapping if you want team features.\")\n",
    "else:\n",
    "    print(\"team_name column available.\")\n",
    "\n",
    "# ---------- Build driver-level & team-level aggregated features from training set ----------\n",
    "# Aggregations we want (per driver_number and per team_name if available)\n",
    "# If team_name missing, create team column from driver mapping file if available\n",
    "if not has_team_name:\n",
    "    mapping_path = DATA_DIR / \"driver_team_mapping.csv\"\n",
    "    if mapping_path.exists():\n",
    "        mapping = pd.read_csv(mapping_path)\n",
    "        # expect columns: driver_number, team\n",
    "        if \"team\" in mapping.columns:\n",
    "            train_df = train_df.merge(mapping[[\"driver_number\",\"team\"]], on=\"driver_number\", how=\"left\")\n",
    "            test_df = test_df.merge(mapping[[\"driver_number\",\"team\"]], on=\"driver_number\", how=\"left\")\n",
    "            has_team_name = True\n",
    "            train_df = train_df.rename(columns={\"team\":\"team_name\"})\n",
    "            test_df = test_df.rename(columns={\"team\":\"team_name\"})\n",
    "            print(\"Loaded driver_team_mapping.csv and merged team info.\")\n",
    "        else:\n",
    "            print(\"driver_team_mapping.csv exists but lacks 'team' column. Skipping team features.\")\n",
    "    else:\n",
    "        print(\"No driver_team_mapping.csv found. Team-level features will be skipped.\")\n",
    "\n",
    "# Create driver aggregates\n",
    "driver_aggs = train_df.groupby(\"driver_number\").agg(\n",
    "    driver_avg_lap = (\"lap_duration\",\"mean\"),\n",
    "    driver_best_lap = (\"lap_duration\",\"min\"),\n",
    "    driver_median_lap = (\"lap_duration\",\"median\"),\n",
    "    driver_std_lap = (\"lap_duration\",\"std\"),\n",
    "    driver_avg_s1 = (\"duration_sector_1\",\"mean\"),\n",
    "    driver_avg_s2 = (\"duration_sector_2\",\"mean\"),\n",
    "    driver_avg_s3 = (\"duration_sector_3\",\"mean\"),\n",
    "    driver_avg_i1 = (\"i1_speed\",\"mean\"),\n",
    "    driver_avg_i2 = (\"i2_speed\",\"mean\"),\n",
    "    driver_avg_st = (\"st_speed\",\"mean\"),\n",
    "    driver_total_laps = (\"lap_duration\",\"count\")\n",
    ").reset_index()\n",
    "\n",
    "driver_aggs[\"driver_consistency\"] = 1 / (driver_aggs[\"driver_std_lap\"].replace(0, np.nan))\n",
    "driver_aggs = driver_aggs.fillna(0)\n",
    "\n",
    "# Create team aggregates (if available)\n",
    "if has_team_name:\n",
    "    team_aggs = train_df.groupby(\"team_name\").agg(\n",
    "        team_avg_lap = (\"lap_duration\",\"mean\"),\n",
    "        team_best_lap = (\"lap_duration\",\"min\"),\n",
    "        team_avg_s1 = (\"duration_sector_1\",\"mean\"),\n",
    "        team_avg_s2 = (\"duration_sector_2\",\"mean\"),\n",
    "        team_avg_s3 = (\"duration_sector_3\",\"mean\"),\n",
    "        team_avg_i1 = (\"i1_speed\",\"mean\"),\n",
    "        team_avg_i2 = (\"i2_speed\",\"mean\"),\n",
    "        team_avg_st = (\"st_speed\",\"mean\"),\n",
    "        team_total_laps = (\"lap_duration\",\"count\")\n",
    "    ).reset_index()\n",
    "else:\n",
    "    team_aggs = None\n",
    "\n",
    "print(\"Driver aggregates:\", driver_aggs.shape)\n",
    "if team_aggs is not None:\n",
    "    print(\"Team aggregates:\", team_aggs.shape)\n",
    "\n",
    "# Merge aggregates into train and test\n",
    "train_df = train_df.merge(driver_aggs, on=\"driver_number\", how=\"left\")\n",
    "test_df = test_df.merge(driver_aggs, on=\"driver_number\", how=\"left\")  # driver's historical stats (from earlier races)\n",
    "\n",
    "if team_aggs is not None:\n",
    "    train_df = train_df.merge(team_aggs, on=\"team_name\", how=\"left\")\n",
    "    test_df = test_df.merge(team_aggs, on=\"team_name\", how=\"left\")\n",
    "\n",
    "# ---------- Optionally add simple track-type features ----------\n",
    "# If you have a mapping file of meeting_key -> track_type ('Street'/'Permanent'/'HighSpeed'), load it.\n",
    "track_meta_path = DATA_DIR / \"track_metadata.csv\"\n",
    "if track_meta_path.exists():\n",
    "    track_meta = pd.read_csv(track_meta_path)\n",
    "    # must contain columns: meeting_key, track_type\n",
    "    if \"meeting_key\" in track_meta.columns and \"track_type\" in track_meta.columns:\n",
    "        train_df = train_df.merge(track_meta[[\"meeting_key\",\"track_type\"]], on=\"meeting_key\", how=\"left\")\n",
    "        test_df = test_df.merge(track_meta[[\"meeting_key\",\"track_type\"]], on=\"meeting_key\", how=\"left\")\n",
    "        print(\"Merged track_type metadata.\")\n",
    "    else:\n",
    "        print(\"track_metadata.csv present but missing required cols. Skipping track_type.\")\n",
    "else:\n",
    "    print(\"No track_metadata.csv found. You can add: meeting_key, track_type to improve model (Street/Perm/HighSpeed).\")\n",
    "\n",
    "# ---------- Define features to use ----------\n",
    "# Base lap-level features (per-row)\n",
    "base_features = [\n",
    "    \"lap_number\",\n",
    "    \"duration_sector_1\",\"duration_sector_2\",\"duration_sector_3\",\n",
    "    \"i1_speed\",\"i2_speed\",\"st_speed\"\n",
    "]\n",
    "\n",
    "# Add driver/team aggregates\n",
    "driver_features = [\n",
    "    \"driver_avg_lap\",\"driver_best_lap\",\"driver_median_lap\",\"driver_consistency\",\"driver_total_laps\",\n",
    "    \"driver_avg_s1\",\"driver_avg_s2\",\"driver_avg_s3\",\"driver_avg_i1\",\"driver_avg_i2\",\"driver_avg_st\"\n",
    "]\n",
    "\n",
    "team_features = []\n",
    "if team_aggs is not None:\n",
    "    team_features = [\n",
    "        \"team_avg_lap\",\"team_best_lap\",\"team_total_laps\",\n",
    "        \"team_avg_s1\",\"team_avg_s2\",\"team_avg_s3\",\"team_avg_i1\",\"team_avg_i2\",\"team_avg_st\"\n",
    "    ]\n",
    "\n",
    "# track_type if present (categorical)\n",
    "has_track_type = \"track_type\" in train_df.columns\n",
    "\n",
    "feature_cols = base_features + driver_features + team_features\n",
    "if has_track_type:\n",
    "    feature_cols.append(\"track_type\")\n",
    "\n",
    "print(\"Final feature columns used:\", feature_cols)\n",
    "\n",
    "# Drop rows with NaN in critical features\n",
    "train_df = train_df.dropna(subset=base_features + [\"lap_duration\"])\n",
    "test_df = test_df.dropna(subset=base_features + [\"lap_duration\"])\n",
    "\n",
    "# ---------- Prepare X/y ----------\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[\"lap_duration\"].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df[\"lap_duration\"].copy()\n",
    "\n",
    "# ---------- Build preprocessing + model pipeline ----------\n",
    "# Categorical: track_type if present\n",
    "categorical_cols = [\"track_type\"] if has_track_type else []\n",
    "numeric_cols = [c for c in feature_cols if c not in categorical_cols]\n",
    "\n",
    "# Simple pipeline: scale not strictly required for RandomForest, but keep one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"model\", rf)\n",
    "])\n",
    "\n",
    "# ---------- Hyperparameter tuning (randomized, fast) ----------\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [100,200,400],\n",
    "    \"model__max_depth\": [6,10,15, None],\n",
    "    \"model__min_samples_split\": [2,5,10],\n",
    "    \"model__min_samples_leaf\": [1,2,4]\n",
    "}\n",
    "\n",
    "print(\"Starting RandomizedSearchCV (this may take a little while)...\")\n",
    "rs = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
    "                        n_iter=12, cv=3, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "best_model = rs.best_estimator_\n",
    "\n",
    "# ---------- Predict on test laps ----------\n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "# ---------- Evaluate per-lap ----------\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(f\"Per-lap MAE: {mae:.4f} s, RMSE: {rmse:.4f} s\")\n",
    "\n",
    "# Save model\n",
    "model_out = DATA_DIR / f\"rf_model_up_to_race_{race_to_predict-1}_predict_race_{race_to_predict}.pkl\"\n",
    "joblib.dump(best_model, model_out)\n",
    "print(\"Saved model to:\", model_out)\n",
    "\n",
    "# ---------- Reduce to per-driver predicted best lap (qualifying best) ----------\n",
    "test_df = test_df.copy()\n",
    "test_df[\"pred_lap\"] = preds\n",
    "# For actual best lap per driver:\n",
    "actual_best = test_df.groupby(\"driver_number\")[\"lap_duration\"].min().reset_index().rename(columns={\"lap_duration\":\"actual_best\"})\n",
    "pred_best = test_df.groupby(\"driver_number\")[\"pred_lap\"].min().reset_index().rename(columns={\"pred_lap\":\"predicted_best\"})\n",
    "comparison = actual_best.merge(pred_best, on=\"driver_number\", how=\"inner\")\n",
    "\n",
    "# If driver_name exists add it\n",
    "if \"driver_name\" in test_df.columns:\n",
    "    driver_names = test_df[[\"driver_number\",\"driver_name\"]].drop_duplicates(\"driver_number\")\n",
    "    comparison = comparison.merge(driver_names, on=\"driver_number\", how=\"left\")\n",
    "\n",
    "# Add delta & rank orders\n",
    "comparison[\"error\"] = comparison[\"predicted_best\"] - comparison[\"actual_best\"]\n",
    "comparison[\"abs_error\"] = comparison[\"error\"].abs()\n",
    "comparison[\"actual_rank\"] = comparison[\"actual_best\"].rank(method=\"min\").astype(int)\n",
    "comparison[\"pred_rank\"] = comparison[\"predicted_best\"].rank(method=\"min\").astype(int)\n",
    "comparison[\"pos_error\"] = (comparison[\"pred_rank\"] - comparison[\"actual_rank\"]).abs()\n",
    "\n",
    "# Sort by actual rank\n",
    "comparison = comparison.sort_values(\"actual_rank\")\n",
    "comparison.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\nPer-driver best-lap comparison (top rows):\")\n",
    "display_cols = [\"driver_number\",\"driver_name\",\"actual_best\",\"predicted_best\",\"error\",\"abs_error\",\"actual_rank\",\"pred_rank\",\"pos_error\"] \\\n",
    "               if \"driver_name\" in comparison.columns else [\"driver_number\",\"actual_best\",\"predicted_best\",\"error\",\"abs_error\",\"actual_rank\",\"pred_rank\",\"pos_error\"]\n",
    "display(comparison[display_cols].head(20))\n",
    "\n",
    "# ---------- Metrics on per-driver predictions ----------\n",
    "mae_driver = comparison[\"abs_error\"].mean()\n",
    "pos_mae = comparison[\"pos_error\"].mean()\n",
    "percent_correct_top1 = (comparison[\"pos_error\"]==0).sum() / len(comparison)\n",
    "\n",
    "print(f\"\\nPer-driver MAE (sec): {mae_driver:.3f}\")\n",
    "print(f\"Mean absolute position error: {pos_mae:.3f} (positions)\")\n",
    "print(f\"Percent exact position predicted: {percent_correct_top1*100:.1f}%\")\n",
    "\n",
    "# ---------- Save results and plots ----------\n",
    "out_csv = DATA_DIR / f\"predictions_race_{race_to_predict}.csv\"\n",
    "comparison.to_csv(out_csv, index=False)\n",
    "print(\"Saved per-driver predictions to:\", out_csv)\n",
    "\n",
    "# Plot predicted vs actual best lap scatter\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(comparison[\"actual_best\"], comparison[\"predicted_best\"])\n",
    "plt.plot([comparison[\"actual_best\"].min(), comparison[\"actual_best\"].max()],\n",
    "         [comparison[\"actual_best\"].min(), comparison[\"actual_best\"].max()], 'r--')\n",
    "plt.xlabel(\"Actual best lap (s)\")\n",
    "plt.ylabel(\"Predicted best lap (s)\")\n",
    "plt.title(f\"Predicted vs Actual best lap (Race {race_to_predict})\")\n",
    "plt.show()\n",
    "\n",
    "# Plot error histogram\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(comparison[\"error\"], bins=20, kde=True)\n",
    "plt.title(\"Distribution of per-driver prediction errors (s)\")\n",
    "plt.xlabel(\"Predicted - Actual (s)\")\n",
    "plt.show()\n",
    "\n",
    "# ---------- Done ----------\n",
    "print(\"Done. Inspect 'predictions_race_{race_to_predict}.csv' and the saved model to reuse for GUI or further analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
